DATE, top_match = `TOP1MATCH*`, top_dist = TOP1DIST,
transect, distance, time_day, days, DURATION
)
}
RJ <- prep_data(read_csv("data/gallus_clusters.csv"))
public_holidays <- as.Date(c("2022-12-31", "2023-01-01","2023-01-02", "2023-01-03", "2023-01-27", "2023-01-28", "2023-01-29", "2023-01-30", "2023-01-31", "2023-02-10", "2023-02-13", "2023-03-01"))
prep_data <- function(df){
df |>
mutate(
transect = as.double(substr(FOLDER, 2,2)),
distance = case_when(
substr(FOLDER, 4, 4) == "5" ~ 50,
substr(FOLDER, 4, 4) == "1" ~ 100,
TRUE ~ 200
),
time_sec = as.numeric(TIME) + OFFSET,
time_day = as_hms(time_sec),
to_classify = weekdays(DATE),
Date = as.Date(DATE, format = "%m/%d/%Y"),
days = case_when(
Date %in% public_holidays ~ "off_day",
to_classify == "Saturday" ~ "off_day",
to_classify == "Sunday" ~ "off_day",
TRUE ~ "weekday")
) |>
dplyr::select(
DATE, top_match = `TOP1MATCH*`, top_dist = TOP1DIST,
transect, distance, time_day, days, DURATION
)
}
RJ <- prep_data(read_csv("data/gallus_clusters.csv"))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readr)
library(hms)
public_holidays <- as.Date(c("2022-12-31", "2023-01-01","2023-01-02", "2023-01-03", "2023-01-27", "2023-01-28", "2023-01-29", "2023-01-30", "2023-01-31", "2023-02-10", "2023-02-13", "2023-03-01"))
prep_data <- function(df){
df |>
mutate(
transect = as.double(substr(FOLDER, 2,2)),
distance = case_when(
substr(FOLDER, 4, 4) == "5" ~ 50,
substr(FOLDER, 4, 4) == "1" ~ 100,
TRUE ~ 200
),
time_sec = as.numeric(TIME) + OFFSET,
time_day = as_hms(time_sec),
to_classify = weekdays(DATE),
Date = as.Date(DATE, format = "%m/%d/%Y"),
days = case_when(
Date %in% public_holidays ~ "off_day",
to_classify == "Saturday" ~ "off_day",
to_classify == "Sunday" ~ "off_day",
TRUE ~ "weekday")
) |>
dplyr::select(
DATE, top_match = `TOP1MATCH*`, top_dist = TOP1DIST,
transect, distance, time_day, days, DURATION
)
}
RJ <- prep_data(read_csv("data/gallus_clusters.csv"))
AK <- prep_data(read_csv("data/koel_clusters.csv"))
RD
RJ
RJ |>
## filter for the top_match
filter(top_match == "chicken") |>
## filter for the disrtance from the cluster
filter(top_dist <= 0.8646)
library(nlme)
RJ_duration_model <- lme(DURATION ~ distance * days + (1|transect),
data = analysis)
RJ_duration_model <- lme(DURATION ~ distance * days + (1|transect),
data = RJ_analysis)
RJ_analysis <- RJ |>
## filter for the top_match
filter(top_match == "chicken") |>
## filter for the disrtance from the cluster
filter(top_dist <= 0.8646)
RJ_duration_model <- lme(DURATION ~ distance * days + (1|transect),
data = RJ_analysis)
?lme
RJ_duration_model <- lme(DURATION ~ distance * days, random = ~1|transect),
RJ_duration_model <- lme(DURATION ~ distance * days, random = ~1|transect,
data = RJ_analysis)
summary(RJ_duration_model)
## diagnostic plot
plot(RJ_duration_model)
## diagnostic plot
plot(RJ_duration_model. resid(.,scaled = T) ~ fitted(.) | transect, abline = 0, lty = 2)
## diagnostic plot
plot(RJ_duration_model, resid(.,scaled = T) ~ fitted(.) | transect, abline = 0, lty = 2)
plot(RJ_duration_model)
qqnorm(RJ_duration_model, abline = c(0, 1), lty = 2)
qqnorm(RJ_duration_model, ~redis(., type = "p") | transect , abline = c(0,1) , lty = 2)
qqnorm(RJ_duration_model, ~redid(., type = "p") | transect , abline = c(0,1) , lty = 2)
qqnorm(RJ_duration_model, ~resid(., type = "p") | transect , abline = c(0,1) , lty = 2)
shapiro.test(RJ_analysis$DURATION)
install.packages("nortest")
library(nortest)
ad.test(RJ_analysis$DURATION)
hist(RJ_analysis$DURATION)
summary(RJ_duration_model)
RJ_analysis
RJ_analysis |>
filter(time_day <= as.hms("10:00:00", format = "%h%m:%s"))
RJ_chorus <- RJ_analysis |>
filter(time_day <= as.hms("10:00:00", format = "%h%m:%s"))
RJ_chorus <- RJ_analysis |>
filter(time_day <= as.hms("10:00:00", format = "%h%m:%s"))  |>
print()
RJ_chorus <- RJ_analysis |>
filter(time_day <= as.hms("10:00:00", format = "%h%m:%s"))  |>
group_by(transect, distance, days) |>
summarise(n = n()) |>
print()
RJ_chorus_model <- glmer(n ~ distance * days, random = ~ 1|transect,
data = RJ_chorus, family = poisson)
?glmer
??glmer
library(lme4)
RJ_chorus_model <- glmer(n ~ distance * days + (1|transect),
data = RJ_chorus, family = poisson)
## rescale variables
RJ_chorus_model.2 <- glmer(scale(n) ~ scale(distance) * days + (1|transect),
data = RJ_chorus, family = poisson)
## rescale variables
RJ_chorus_model.2 <- glmer(n ~ scale(distance) * days + (1|transect),
data = RJ_chorus, family = poisson)
library(DHARMa)
plot(simulateResiduals(RJ_chorus_model.2))
hist(RJ_chorus$n)
plot(simulateResiduals(RJ_chorus_model.2))
RJ_chorus_model.3 <- glmer.nb(n ~ scale(distance) * days + (1|transect), data = RJ_chorus)
plot(simulateResiduals(RJ_chorus_model.3))
summary(RJ_chorus_model.3)
AK
AK_analysis <- AK |>
filter(top_match = "Koel") |>
filter(top_dist <= 1)
AK_analysis <- AK |>
filter(top_match == "Koel") |>
filter(top_dist <= 1)
AK_duration_model <- lme(DURATION ~ distance * days, random = ~1|transect, data = AK_analysis)
### variance for the dataset
plot(AK_duration_model, resid(.,scaled = T) ~ fitted(.) | transect, abline = 0, lty = 2)
plot(RJ_duration_model)
### normality
qqnorm(RJ_duration_model, abline = c(0, 1), lty = 2)
### normality
qqnorm(AK_duration_model, abline = c(0, 1), lty = 2)
qqnorm(AK_duration_model, ~resid(., type = "p") | transect , abline = c(0,1) , lty = 2)
### large enough sample size always reject the null hypothesis?
ad.test(AK_analysis$DURATION)
hist(AK_analysis$DURATION)
### large enough sample size always reject the null hypothesis?
ad.test(log(AK_analysis$DURATION))
hist(log(AK_analysis$DURATION))
AK_duration_model.2 <- lme(log(DURATION) ~ distance * days, random = ~1|transect, data = AK_analysis)
summary(AK_duration_model.2)
AK_chorus <- AK_analysis |>
filter(time_day <= as.hms("10:00:00", format = "%h%m:%s"))  |>
group_by(transect, distance, days) |>
summarise(n = n())
AK_chorus_model.1 <- glmer(n ~ distance * days + (1|transect),
data = AK_chorus, family = poisson)
## rescale variables
AK_chorus_model.2 <- glmer(n ~ scale(distance) * days + (1|transect),
data = AK_chorus, family = poisson)
plot(simulateResiduals(AK_chorus_model.2))
AK_chorus_model.3 <- glmer.nb(n ~ scale(distance) * days + (1|transect), data = AK_chorus)
plot(simulateResiduals(AK_chorus_model.3))
plot(simulateResiduals(AK_chorus_model.2))
plot(simulateResiduals(AK_chorus_model.3))
library(MASS)
AK_chorus_model.4 <- glmmPQL(n ~ scale(distance) * days, random = ~1|transect, data = AK_chorus)
AK_chorus_model.4 <- glmmPQL(n ~ scale(distance) * days, random = ~1|transect,
data = AK_chorus, family = quasipoisson)
summary(AK_chorus_model.4)
AK_chorus_model.5 <- update(AK_chorus_model.4, ~.-scale(distance):distance)
AK_chorus_model.5 <- update(AK_chorus_model.4, ~.-scale(distance):days)
AK_chorus_model.5 <- update(AK_chorus_model.4, ~.-distance:days)
AK_chorus_model.5 <- glmmPQL(n ~ scale(distance) + days, random = ~1|transect,
data = AK_chorus, family = quasipoisson)
summary(AK_chorus_model.5)
AK_duration_model.3 <- lme(log(DURATION) ~ distance + days, random = ~1|transect, data = AK_analysis)
summary(AK_duration_model.2)
summary(AK_duration_model.2)
AK_duration_model.3 <- lme(log(DURATION) ~ distance + days, random = ~1|transect, data = AK_analysis)
summary(AK_duration_model.2)
summary(AK_duration_model.3)
RJ_duration_model.1 <- lme(DURATION ~ distance + days, random = ~1|transect, data = RJ_analysis)
summary(RJ_duration_model.1)
RJ_duration_model.2<- lme(DURATION ~ distance, random = ~1|transect, data = RJ_analysis)
summary(RJ_duration_model.2)
summary(RJ_chorus_model.3)
RJ_chorus_model.4 <- glmer.nb(n ~ scale(distance) + days + (1|transect), data = RJ_chorus)
summary(RJ_chorus_model.4)
AK_chorus_model.6 <- glmmPQL(n ~ days, random = ~1|transect,
data = AK_chorus, family = quasipoisson)
summary(AK_chorus_model.6)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readr)
library(hms)
library(nlme)
library(nortest)
library(lme4)
library(DHARMa)
library(MASS)
public_holidays <- as.Date(c("2022-12-31", "2023-01-01","2023-01-02", "2023-01-03", "2023-01-27", "2023-01-28", "2023-01-29", "2023-01-30", "2023-01-31", "2023-02-10", "2023-02-13", "2023-03-01"))
source("F:/Y4S2/data analysis/Project/Script for Barbet (update 27032023).R", echo=TRUE)
install.packages("hms")
install.packages("rlang")
install.packages("readr")
install.packages("nortest")
install.packages("ggplot2", dependencies = TRUE)
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("nortest")
install.packages("ggplot2", dependencies = TRUE)
library(tidyverse)
library(readr)
library(hms)
library(nlme)
library(nortest)
library(lme4)
library(DHARMa)
library(MASS)
public_holidays <- as.Date(c("2022-12-31", "2023-01-01","2023-01-02", "2023-01-03", "2023-01-27", "2023-01-28", "2023-01-29", "2023-01-30", "2023-01-31", "2023-02-10", "2023-02-13", "2023-03-01"))
prep_data <- function(df){
df |>
mutate(
transect = as.double(substr(FOLDER, 2,2)),
distance = case_when(
substr(FOLDER, 4, 4) == "5" ~ 50,
substr(FOLDER, 4, 4) == "1" ~ 100,
TRUE ~ 200
),
time_sec = as.numeric(TIME) + OFFSET,
time_day = as_hms(time_sec),
to_classify = weekdays(DATE),
Date = as.Date(DATE, format = "%m/%d/%Y"),
days = case_when(
Date %in% public_holidays ~ "off_day",
to_classify == "Saturday" ~ "off_day",
to_classify == "Sunday" ~ "off_day",
TRUE ~ "weekday")
) |>
dplyr::select(
DATE, top_match = `TOP1MATCH*`, top_dist = TOP1DIST,
transect, distance, time_day, days, DURATION
)
}
LB <- prep_data(read_csv("data/barbet_clusters.csv"))
############### BARBET DATA #################
LB_analysis <- LB |>
## filter for the top_match
filter(top_match == "Lineated Barbet 1") |>
## filter for the disrtance from the cluster
filter(top_dist <= 1)
str(LB_analysis)
## Converted <distance> and <transect> and <days> to factors.
# Remove: LB_analysis$distance=as.factor(LB_analysis$distance)
LB_analysis$transect=as.factor(LB_analysis$transect)
LB_analysis$days=as.factor(LB_analysis$days)
str(LB_analysis)
## Fitting the model: LME with <transect> as a random effect.
lb_duration_mod1a=lme(DURATION~distance*days,random=~1|transect,data=LB_analysis)
## Diagnostic plots.
# Variance for whole dataset
plot(lb_duration_mod1a) #looks like there is some heteroscedasticity.
# Variance for levels of random effect
plot(lb_duration_mod1a,resid(.,scaled=T)~fitted(.)|transect,abline=0,lty=2) #equality of variance not very good.
# Normality for whole dataset
qqnorm(lb_duration_mod1a,abline=c(0,1),lty=2) #non-normal.
# Normality for levels of random effect
qqnorm(lb_duration_mod1a,~resid(.,type="p")|transect,abline=c(0,1),lty=2) #non-normal.
## Transform the y-variable <DURATION>.
logDURATION=log(LB_analysis$DURATION)
## Refit the model: LME with <transect> as a random effect.
lb_duration_mod1b=lme(logDURATION~distance*days,random=~1|transect,data=LB_analysis)
## Diagnostic plots.
# Variance for whole dataset
plot(lb_duration_mod1b) #looks ok.
# Variance for levels of random effect
plot(lb_duration_mod1b,resid(.,scaled=T)~fitted(.)|transect,abline=0,lty=2) #equality of variance not very good.
# Normality for whole dataset
qqnorm(lb_duration_mod1b,abline=c(0,1),lty=2) #non-normal.
# Normality for levels of random effect
qqnorm(lb_duration_mod1b,~resid(.,type="p")|transect,abline=c(0,1),lty=2) #non-normal.
## Refit the model: NB GLMM with <transect> as a random effect.
lb_duration_mod2a=glmer.nb(DURATION~distance*days+(1|transect),data=LB_analysis)
plot(simulateResiduals(lb_duration_mod2a)) # many problems with overdispersion, ks-test, equality of variance.
## Refit the model: Quasi-GLMM with <transect> as a random effect.
lb_duration_mod3a=glmmPQL(DURATION~distance*days,random=~1|transect,
family=quasi,data=LB_analysis)
summary(lb_duration_mod3a)
lb_duration_mod3b=update(lb_duration_mod3a,~.-distance:days)
summary(lb_duration_mod3b)
lb_duration_mod3c=update(lb_duration_mod3b,~.-distance)
summary(lb_duration_mod3c)
## Checking plots
plot(DURATION~distance,data=LB_analysis) # Looks like there is no significance
boxplot(DURATION~days,data=LB_analysis) # Looks like there is no significance
ggplot(LB_analysis, aes(x=distance, y=DURATION)) +
geom_point(aes(col=days))
########################## EXPLAIN <N> ##################################
############# WITH <DISTANCE> AND <DAYS> WITH <TRANSECT> ########################
LB_chorus <- LB_analysis |>
filter(time_day <= as.hms("10:00:00", format = "%h%m:%s"))  |>
group_by(transect, distance, days) |>
summarise(n = n())
lb_chorus_mod1a=glmer(n~distance*days+(1|transect),data=LB_chorus,family=poisson)
## Rescale variables
lb_chorus_mod2a=glmer(n~scale(distance)*days+(1|transect),
data=LB_chorus,family=poisson)
plot(simulateResiduals(lb_chorus_mod2a)) # no problems.
summary(lb_chorus_mod2a)
lb_chorus_mod2b=update(lb_chorus_mod2a,~.-scale(distance):days)
summary(lb_chorus_mod2b)
lb_chorus_mod2c=update(lb_chorus_mod2b,~.-days)
summary(lb_chorus_mod2c)
AIC(lb_chorus_mod2a, lb_chorus_mod2b, lb_chorus_mod2c)
library(ggplot2)
ggplot(LB_chorus,aes(x=days,y=n))+geom_boxplot(aes(col=distance))
ggplot(LB_chorus,aes(x=distance,y=n))+geom_boxplot(aes(col=days))
############################## ANALYSIS ########################################
summary(lb_duration_mod3c)
summary(lb_chorus_mod2a)
# dawn chorus not significantly affected by <scale(distance)> nor <days>,
# dawn chorus not significantly affected by <scale(distance)> nor <days>,
# but the interaction makes sense even though its not significant.
# dawn chorus not significantly affected by <scale(distance)> nor <days>,
# but the interaction makes sense even though its not significant.
# dawn chorus not significantly affected by <scale(distance)> nor <days>,
# but the interaction makes sense even though its not significant.
LB_duration_model.2 <- lme(DURATION ~ b1(distance, 100) * days + b2(distance, 100) * days, random = ~1|transect, data = LB_analysis)
bp <- 100
b1 <- function(x, bp) ifelse(x < bp, x, 0)
b2 <- function(x, bp) ifelse(x < bp, 0, x)
LB_duration_model.2 <- lme(DURATION ~ b1(distance, 100) * days + b2(distance, 100) * days, random = ~1|transect, data = LB_analysis)
BB_duration_model.3 <- lme(DURATION ~ b1(distance, 100) + b2(distance, 100) + days, random = ~1|transect, data = LB_analysis)
LB_duration_model.2 <- lme(DURATION ~ b1(distance, 100) * days + b2(distance, 100) * days, random = ~1|transect, data = LB_analysis)
LB_duration_model.3 <- lme(DURATION ~ b1(distance, 100) + b2(distance, 100) + days, random = ~1|transect, data = LB_analysis)
summary(LB_duration_model.2)
summary(LB_duration_model.2)
summary(LB_duration_model.3)
AIC(LB_duration_model.2, LB_duration_model.3)
summary(lb_chorus_mod2c)
library(tidyverse)
library(readr)
library(hms)
library(nlme)
library(nortest)
library(lme4)
library(DHARMa)
library(MASS)
public_holidays <- as.Date(c("2022-12-31", "2023-01-01","2023-01-02", "2023-01-03", "2023-01-27", "2023-01-28", "2023-01-29", "2023-01-30", "2023-01-31", "2023-02-10", "2023-02-13", "2023-03-01"))
prep_data <- function(df){
df |>
mutate(
transect = as.double(substr(FOLDER, 2,2)),
distance = case_when(
substr(FOLDER, 4, 4) == "5" ~ 50,
substr(FOLDER, 4, 4) == "1" ~ 100,
TRUE ~ 200
),
time_sec = as.numeric(TIME) + OFFSET,
time_day = as_hms(time_sec),
to_classify = weekdays(DATE),
Date = as.Date(DATE, format = "%m/%d/%Y"),
days = case_when(
Date %in% public_holidays ~ "off_day",
to_classify == "Saturday" ~ "off_day",
to_classify == "Sunday" ~ "off_day",
TRUE ~ "weekday")
) |>
dplyr::select(
DATE, top_match = `TOP1MATCH*`, top_dist = TOP1DIST,
transect, distance, time_day, days, DURATION
)
}
LB <- prep_data(read_csv("data/barbet_clusters.csv"))
############### BARBET DATA #################
LB_analysis <- LB |>
## filter for the top_match
filter(top_match == "Lineated Barbet 1") |>
## filter for the disrtance from the cluster
filter(top_dist <= 1)
str(LB_analysis)
## Converted <distance> and <transect> and <days> to factors.
# Remove: LB_analysis$distance=as.factor(LB_analysis$distance)
LB_analysis$transect=as.factor(LB_analysis$transect)
LB_analysis$days=as.factor(LB_analysis$days)
str(LB_analysis)
########################## EXPLAIN <DURATION> ##################################
############# WITH <DISTANCE> AND <DAYS> WITH <TRANSECT> ########################
## Fitting the model: LME with <transect> as a random effect.
lb_duration_mod1a=lme(DURATION~distance*days,random=~1|transect,data=LB_analysis)
## Diagnostic plots.
# Variance for whole dataset
plot(lb_duration_mod1a) #looks like there is some heteroscedasticity.
# Variance for levels of random effect
plot(lb_duration_mod1a,resid(.,scaled=T)~fitted(.)|transect,abline=0,lty=2) #equality of variance not very good.
# Normality for whole dataset
qqnorm(lb_duration_mod1a,abline=c(0,1),lty=2) #non-normal.
# Normality for levels of random effect
qqnorm(lb_duration_mod1a,~resid(.,type="p")|transect,abline=c(0,1),lty=2) #non-normal.
##################################
## Transform the y-variable <DURATION>.
logDURATION=log(LB_analysis$DURATION)
## Refit the model: LME with <transect> as a random effect.
lb_duration_mod1b=lme(logDURATION~distance*days,random=~1|transect,data=LB_analysis)
## Diagnostic plots.
# Variance for whole dataset
plot(lb_duration_mod1b) #looks ok.
# Variance for levels of random effect
plot(lb_duration_mod1b,resid(.,scaled=T)~fitted(.)|transect,abline=0,lty=2) #equality of variance not very good.
# Normality for whole dataset
qqnorm(lb_duration_mod1b,abline=c(0,1),lty=2) #non-normal.
# Normality for levels of random effect
qqnorm(lb_duration_mod1b,~resid(.,type="p")|transect,abline=c(0,1),lty=2) #non-normal.
## Note: transforming <distance> using log(y), sqrt(y), and 1/y did not help.
## Proceed to fit a GLMM instead.
##################################
## Refit the model: NB GLMM with <transect> as a random effect.
lb_duration_mod2a=glmer.nb(DURATION~distance*days+(1|transect),data=LB_analysis)
plot(simulateResiduals(lb_duration_mod2a)) # many problems with overdispersion, ks-test, equality of variance.
##################################
## Refit the model: Quasi-GLMM with <transect> as a random effect.
lb_duration_mod3a=glmmPQL(DURATION~distance*days,random=~1|transect,
family=quasi,data=LB_analysis)
summary(lb_duration_mod3a)
lb_duration_mod3b=update(lb_duration_mod3a,~.-distance:days)
summary(lb_duration_mod3b)
lb_duration_mod3c=update(lb_duration_mod3b,~.-distance)
summary(lb_duration_mod3c)
# Ask friends for help: which model is better -> include <distance> p-value=0.0735
## Checking plots
plot(DURATION~distance,data=LB_analysis) # Looks like there is no significance
boxplot(DURATION~days,data=LB_analysis) # Looks like there is no significance
ggplot(LB_analysis, aes(x=distance, y=DURATION)) +
geom_point(aes(col=days))
# No diagnostic plots nor AIC() so we will use lb_duration_mod3c.
########################## EXPLAIN <N> ##################################
############# WITH <DISTANCE> AND <DAYS> WITH <TRANSECT> ########################
LB_chorus <- LB_analysis |>
filter(time_day <= as.hms("10:00:00", format = "%h%m:%s"))  |>
group_by(transect, distance, days) |>
summarise(n = n())
lb_chorus_mod1a=glmer(n~distance*days+(1|transect),data=LB_chorus,family=poisson)
## Rescale variables
lb_chorus_mod2a=glmer(n~scale(distance)*days+(1|transect),
data=LB_chorus,family=poisson)
plot(simulateResiduals(lb_chorus_mod2a)) # no problems.
summary(lb_chorus_mod2a)
## Note: scale(distance):days p-value 0.0646, close to 0.05
lb_chorus_mod2b=update(lb_chorus_mod2a,~.-scale(distance):days)
summary(lb_chorus_mod2b)
lb_chorus_mod2c=update(lb_chorus_mod2b,~.-days)
summary(lb_chorus_mod2c)
AIC(lb_chorus_mod2a, lb_chorus_mod2b, lb_chorus_mod2c)
# first model has lowest AIC score, but third model is the simplest.
# 183.1729-182.6469 # 0.526
# Ask Prof Ian: which model to use?
library(ggplot2)
ggplot(LB_chorus,aes(x=days,y=n))+geom_boxplot(aes(col=distance))
ggplot(LB_chorus,aes(x=distance,y=n))+geom_boxplot(aes(col=days))
# Based on the boxplot, there seems to be an interaction between <distance> and <days>, that's why R tells
# you to keep the interaction in AIC(). Makes sense to use the model with the interaction, but this makes it
# hard to use the effect sizes. Perhaps report the averages (mean no. of vocalisations at each level of <distance>).
# Use lb_chorus_mod2a.
############################## ANALYSIS ########################################
summary(lb_duration_mod3c)
# duration significantly affected by <days>
summary(lb_chorus_mod2a)
# dawn chorus not significantly affected by <scale(distance)> nor <days>,
# but the interaction makes sense even though its not significant.
#### piecewise regression
bp <- 100
b1 <- function(x, bp) ifelse(x <= bp, x, 0)
b2 <- function(x, bp) ifelse(x < bp, 0, x)
LB_duration_model.2 <- lme(DURATION ~ b1(distance, 100) * days + b2(distance, 100) * days, random = ~1|transect, data = LB_analysis)
LB_duration_model.3 <- lme(DURATION ~ b1(distance, 100) + b2(distance, 100) + days, random = ~1|transect, data = LB_analysis)
summary(LB_duration_model.2)
summary(LB_duration_model.3)
AIC(LB_duration_model.2, LB_duration_model.3)
LB_duration_model.2 <- lme(DURATION ~ b1(distance, 100) * days + b2(distance, 100) * days, random = ~1|transect, data = LB_analysis)
LB_duration_model.3 <- lme(DURATION ~ b1(distance, 100) + b2(distance, 100) + days, random = ~1|transect, data = LB_analysis)
summary(LB_duration_model.2)
summary(LB_duration_model.2)
summary(LB_duration_model.3)
LB_n_model.2 <- glmer(n ~ b1(distance, 100) * days + b2(distance, 100) * days, random = ~1|transect, data = LB_analysis)
LB_n_model.2 <- glmer(n ~ b1(distance, 100) * days + b2(distance, 100) * days + (1|transect), data = LB_analysis)
LB_n_model.2 <- glmer(n ~ b1(distance, 100) * days + b2(distance, 100) * days + (1|transect), data = LB_analysis, family = poisson)
View(LB_analysis)
LB_n_model.2 <- glmer(n ~ b1(distance, 100) * days + b2(distance, 100) * days + (1|transect), data = LB_chorus, family = poisson)
LB_n_model.2 <- glmer(n ~ scale(b1(distance, 100)) * days + scale(b2(distance, 100)) * days + (1|transect), data = LB_chorus, family = poisson)
LB_n_model.3 <- glmer(n ~ scale(b1(distance, 100)) + scale(b2(distance, 100)) + days + (1|transect), data = LB_chorus, family = poisson)
summary(LB_n_model.2)
summary(LB_n_model.3)
plot(simulateResiduals(LB_n_model.3))
plot(simulateResiduals(LB_duration_model.3)
plot(simulateResiduals(LB_n_model.3))
plot(simulateResiduals(LB_duration_model.3))
plot(LB_duration_model.3)
LB_duration_model.4 <-glmer.nb(DURATION ~ b1(distance, 100) + b2(distance, 100) + days, random = ~1|transect, data = LB_analysis)
LB_duration_model.4 <-glmer.nb(DURATION ~ b1(distance, 100) + b2(distance, 100) + days + (1|transect), data = LB_analysis)
summary(LB_duration_model.4)
LB_duration_model.4 <-glmer.nb(DURATION ~ scale(b1(distance, 100)) + scale(b2(distance, 100)) + days + (1|transect), data = LB_analysis)
summary(LB_duration_model.4)
